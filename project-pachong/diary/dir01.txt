---------------------爬虫介绍--------------------------
爬虫究竟是合法还是违法的
-- 在法律中是不被禁止
-- 具有违法风险
-- 恶意爬虫 善意爬虫

爬虫带来的风险可以提现在以下两个方面
-- 爬虫干扰了被访问网站的正常运行
-- 爬虫抓取了受到法律保护的特定类型的数据或信息

如何在使用编写爬虫的过程中避免触犯法律
-- 时常优化自己的程序,避免干扰被访问网站的正常运行
-- 在使用,传播爬取的数据时,审查抓取数据的内容,如发现涉及用户隐私商业机密等敏感内容需要及时停止爬取和传播

爬虫使用场景的分类
-- 通用爬虫:抓取系统重要组成部分,抓取的是一整张页面数据
-- 聚焦爬虫:是建立在通用爬虫的基础之上,抓取的是页面中特定的局部内容
-- 增量式爬虫:检测网站中数据更新的情况,只会抓取网站中最新更新的数据

爬虫的矛与盾
-- 反爬机制:门户网站,可以通过指定相应的策略或者技术手段,防止爬虫程序进行网站数据的获取
-- 反反爬策略:爬虫程序可以通过制定相关的策略或者技术手段,破解门户网站中的反爬机制,从而获取门户中的数据
-- robots.txt协议:君子协议,规定网站中哪些数据可以被爬虫爬取,哪些不可以被爬取
---------------------网络传输协议介绍--------------------------
http协议:服务器和客户端进行数据交互的一种形式

常用的请求头信息:
-- User-Agent: 请求载体的身份标识
-- Connection: 请求完毕后,是断开连接还是保持连接

常用的响应头信息:
-- Content-Type: 服务器响应回客户端的数据类型

https协议:安全的超文本传输协议
加密方式:
-- 对称秘钥加密
-- 非对称秘钥加密
-- 证书秘钥加密
--------------------requests模块---------------------------
requests模块:
    -- urllib模块
    -- requests模块
requests模块:python中原生的一款基于网络请求的模块,功能非常强大,简单便捷,效率极高
作用: 模拟浏览器发送请求
如何使用:
    -- 指定url
    -- 发起请求
    -- 获取响应数据
    -- 持久化存储
环境安装: pip install requests
实战编码:
    -- 需求:爬取搜狗首页的信息

实战巩固
    -- 需求: 爬取搜狗指定词条对应的搜索结果页面(简易网页采集器)
        -- UA检测
        -- UA伪装
    -- 需求: 破解百度翻译
        -- post请求(携带参数)
        -- 响应数据是一组json数据
    -- 需求: 爬取豆瓣电影分类排行榜 https://movie.douban.com/
    -- 需求: 爬取肯德基餐厅查询http://www.kfc.com.cn/kfccda/index.aspx中指定地点的餐厅数
    -- 需求: 爬取国家药品监督管理总局中基于中华人民共和国化妆品生产许可证相关数据http://125.
-----------------------------------------------
